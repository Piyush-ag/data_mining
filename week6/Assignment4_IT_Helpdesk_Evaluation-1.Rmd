---
title: "Assignment 4"
author: "Piyush Agrawal"
output:
  word_document: default
  html_notebook: default 
editor_options: 
  markdown: 
    wrap: 72
---

# Set-up

Load packages.

```{r}
rm(list = ls())
library(readxl)
library(tidyverse)
library(ggplot2)
```

For this and the next assignments (Assignment 3 and 4), you will use the
dataset from
<https://www.ibm.com/communities/analytics/watson-analytics-blog/it-help-desk/>.
(the link is now invalid.) This data is from an Information Technology
(IT) department interested in improving the satisfaction of customers.\
To start their analysis, they constructed this data set of 100,000
closed tickets that were filed at their help desk.

Load the dataset and save it as ithelp.

```{r}
ithelp <- read_excel("WA_Fn-UseC_-IT-Help-Desk.xlsx")
```

```{r}
glimpse(ithelp)
```

A total of 100,000 rows. Each row represent an individual request. The
data includes:

-   Requestor: employee who submitted the ticket
-   RequestorSeniority: employeeâ€™s seniority within the company
-   ITOwner: IT employee who serviced the ticket
-   FileAgainst: functional area against which the ticket was filed
    (systems, software, hardware, access)
-   TicketType: whether the ticket was a request for new services or an
    issue with existing services
-   Severity: submitter-assigned severity of the ticket
-   Priority: IT-assigned priority of the ticket
-   daysOpen: number of days the ticket was open
-   Satisfaction: satisfaction with the resolution of the ticket
    (reported by the submitter)

```{r}
summary(ithelp)
```

Some 'character' variables behave unexpectedly. Let's convert all
character variables into factors, which indicate categorical variables
in R.

```{r}
ithelp<-ithelp%>%
  mutate(ticket=as.factor(ticket),
         Requestor=as.factor(Requestor),
         RequestorSeniority=as.factor(RequestorSeniority),
         ITOwner=as.factor(ITOwner),
         FiledAgainst=as.factor(FiledAgainst),
         TicketType=as.factor(TicketType),
         Severity=as.factor(Severity),
         Priority=as.factor(Priority),
         Satisfaction=as.factor(Satisfaction))
```

Let's check the summary again.

```{r}
summary(ithelp)
```

It turns out that there are many cases with "Unknown" Satisfaction.
Let's exclude these cases from the analysis (Step 1: filter). Next, we
may build a multi-class classification model (Unsatisfied, Satisfied,
Highly satisfied), but let's simplify it to a binary classifier and
identify "Unsatisfied" cases, which are problematic. Create a new
variable, "negative", which indicates if a user's feedback is negative
(Step 2: mutate). The following code will do these jobs for you.

```{r}
ithelp<-ithelp%>%
  filter(Satisfaction!="0 - Unknown")%>%
  mutate(negative=as.factor(ifelse(Satisfaction =="1 - Unsatisfied","Yes","No")))

summary(ithelp)
```

# Set up for holdout validation

Let's select 20% of dataset. Using these indices, we will create a test
and a training dataset.

```{r}
set.seed(1)   # set a random seed 
index <- sample(nrow(ithelp), nrow(ithelp)*0.2) # random selection of indices. 
test <- ithelp[index,]       # save 20% as a test dataset
training <-ithelp[-index,]   # save the rest as a training set

```

# Tree model

```{r}
library(rpart)
library(rpart.plot)
```

Build the same model to predict "negative", with the following
variables. \* RequestorSeniority \* FiledAgainst \* TicketType \*
Severity \* Priority \* daysOpen

But this time, we will make two changes. 1. Instead of the entire
dataset for training (ithelp), you will use the training dataset
(training). 2. Generate a bigger tree with cp=0. Set
`control=rpart.control(cp=0)`.

Save the model as `ct_model`. We will skip plotting the tree. It may
crash.

```{r}
ct_model<-rpart(negative~RequestorSeniority+FiledAgainst+TicketType+Severity+Priority+daysOpen,           # model formula
                data=training,                     # dataset
                method="class",                   # "class" indicates a classification tree model 
                control=rpart.control(cp=0))   # tree control parameters. 
```

Check the cross-validation result using `printcp()`.

```{r}
printcp(ct_model)
```

Prune the tree using the cp value with the minimum xerror. Save the
result as `min_xerror_tree`.

```{r}

min_cp <- ct_model$cptable[which.min(ct_model$cptable[, "xerror"]), "CP"]
min_xerror_tree <- prune(ct_model, cp = min_cp)


```

Apply this model to the test dataset to get the predicted probabilities.

```{r}
tree_probs <- predict(min_xerror_tree, test, type = "prob")[, "Yes"]
```

Using the 50% cut-off, generate class prediction.

```{r}
tree_preds <- ifelse(tree_probs > 0.5, "Yes", "No")
tree_preds <- as.factor(tree_preds)
```

## Question 1. What is the error rate of this model when we use the 50% cut-off?

```{r}
error_rate <- mean(tree_preds != test$negative)
error_rate  # This will print the error rate as a proportion

```

## Question 2. Generate a confusion table of this model. What is the false positive rate of this model?

```{r}
conf_matrix <- table(Predicted = tree_preds, Actual = test$negative)
conf_matrix

# False Positive Rate = FP / (FP + TN)
false_positive_rate <- conf_matrix["Yes", "No"] / (conf_matrix["Yes", "No"] + conf_matrix["No", "No"])
false_positive_rate
```

# Logit Regression Model

Using the training dataset, build a logit regression model to predict
"negative", with the following variables. \* RequestorSeniority \*
FiledAgainst \* TicketType \* Severity \* Priority \* daysOpen

Again, be sure to use \`training' dataset for model building.

```{r}
logit_model<-glm(negative~RequestorSeniority+FiledAgainst+TicketType+Severity+Priority+daysOpen,              # model formula
                       data=training,
                 family="binomial")
summary(logit_model)
```

Apply this model to the test dataset to get the predicted probabilities.

```{r}
logit_probs <- predict(logit_model, newdata = test, type = "response")
logit_preds <- ifelse(logit_probs > 0.5, "Yes", "No")
logit_preds <- as.factor(logit_preds)
```

# Performance Visualization with ROC

Plot ROC curves of the tree model and logit regression mode you
developed.

```{r}
# install.packages("pROC")
library(pROC)

# Tree model ROC
tree_roc <- roc(response = test$negative, predictor = tree_probs)
plot(tree_roc, col = "blue", main = "ROC Curves: Tree vs. Logistic")
auc_tree <- auc(tree_roc)

# Logistic regression ROC
logit_roc <- roc(response = test$negative, predictor = logit_probs)
lines(logit_roc, col = "red")
legend("bottomright", legend = c("Tree", "Logit"), col = c("blue", "red"), lwd = 2)

auc_logit <- auc(logit_roc)

auc_tree
auc_logit
```

## Question 3. What are AUCs of the classification tree model?

Area under the curve: 0.564

## Question 4. What are AUCs of the logit regression model?

Area under the curve: 0.6292

## Question 5 The same as the previous assignments, your last task is creating a report. Change the author name on the top of this R markdown file to yours. Compile this R markdown file into a Word document and submit it through the course Canvas.
